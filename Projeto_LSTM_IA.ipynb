{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40b90843"
      },
      "source": [
        "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# ***M√∫sica generativa em LSTM***\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYx9D4GZA5o9",
        "cellView": "form"
      },
      "source": [
        "#@title **Identifica√ß√£o do Grupo**\n",
        "\n",
        "Aluno1 = '10390339, Leonardo Biagiotti Beloti' #@param {type:\"string\"}\n",
        "Aluno2 = '10389222, Lucas Damasceno da Cunha Lima' #@param {type:\"string\"}\n",
        "Aluno3 = '10389472, Lucas Iudi Corregliano Gallinari' #@param {type:\"string\"}\n",
        "Aluno4 = '10389723, Thiago Aidar Figueiredo' #@param {type:\"string\"}\n",
        "Aluno5 = '10388769, Yiou Wu' #@param {type:\"string\"}\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Resumo (*Abstract*)**\n",
        "\n",
        "Este projeto tem como objetivo gerar m√∫sicas a partir da  de redes neurais artificiais Long-Short Term Memory (LSTM). A t√©cnica de web scraping foi aplicada no processo de obten√ß√£o das obras em colet√¢neas MIDI. No pr√©-processamento dos arquivos MIDI, as m√∫sicas foram transpostas para a mesma tonalidade com a finalidade da redu√ß√£o de dimensionalidade do dataset, diminuindo a quantidade de notas √∫nicas. Foi utilizada uma estrutura para armazenar as notas e acordes com informa√ß√µes de seu tom, dura√ß√£o e o tempo decorrido em rela√ß√£o ao √∫ltimo evento (offset). Essas informa√ß√µes foram convertidas em s√©ries temporais como entrada para o treinamento dos modelos e gera√ß√£o de sequ√™ncias musicais. Foi utilizada a rede neural proposta por Jordan Bird para a gera√ß√£o musical."
      ],
      "metadata": {
        "id": "JlCIc2YooBW7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4-f8AtfKAn2"
      },
      "source": [
        "# **Referencial Te√≥rico**\n",
        "\n",
        "## **MIDI**\n",
        "Um arquivo em formato MIDI usa de seu pr√≥prio protocolo de comunica√ß√£o para intera√ß√µes de instrumentos eletr√¥nicos em um ambiente digital, permitindo o armazenamento e manipula√ß√£o de obras musicais por um baixo custo. O formato cont√©m quatro par√¢metros que definem os eventos de uma composi√ß√£o: NOTE_ON, NOTE_OFF, VELOCITY e TIME_SHIFT. A partir destas informa√ß√µes, √© poss√≠vel extrair informa√ß√µes dos eventos que ocorrem dentre composi√ß√µes. Um evento pode conter um NOTE_ON de uma √∫nica nota, assim como o NOTE_ON de um acorde. Pelo parametro de TIME_SHIFT √© poss√≠vel extrair o tempo que cada nota ocorre durante uma composi√ß√£o. A dura√ß√£o de uma nota seria o tempo decorrido entre seu NOTE_ON e NOTE_OFF.\n",
        "\n",
        " ## **S√©rie Temporal**\n",
        "\n",
        " Uma s√©rie temporal pode ser descrita como uma sequ√™ncia de eventos coletados dentre intervalos de tempo regulares. Sua an√°lise busca por padr√µes que ajudem a identificar tend√™ncias e caracter√≠sticas que auxiliam na previs√£o de novos eventos. Uma m√∫sica pode ser representada como tal, a partir da disposi√ß√£o de notas em intervalos regulares de tempo.\n",
        "\n",
        " ## **Rede Neural Artificial**\n",
        "\n",
        " Uma rede neural artificial (ANN) √© um modelo computacional inspirado no sistema nervoso humano, que tem em sua estrutura entradas, neur√¥nios e sa√≠das. Elas s√£o capazes de aprender a realizar tarefas complexas, como reconhecimento de padr√µes, processamento de linguagem natural e, neste caso, ser√° utilizada para a gera√ß√£o de m√∫sica. As ANNs podem ser divididas em feedforward, na qual as informa√ß√µes fluem em uma dire√ß√£o, e recurrent, onde informa√ß√µes podem fluir em qualquer dire√ß√£o, sendo poss√≠vel loopbacks.\n",
        "\n",
        " ## **LSTM**\n",
        "\n",
        " Recurrent Neural Networks (RNNs) s√£o modelos usados para processar dados sequenciais, tendo conex√µes recursivas que permitem capturar depend√™ncias de longo prazo nos dados da sequ√™ncia. Um dos desafios comuns no treinamento de RNNs √© o problema do desaparecimento do gradiente, que ocorre quando o gradiente se torna muito pequeno ou muito grande √† medida que os passos de tempo aumentam durante o backpropagation. Isso torna dif√≠cil treinar RNNs, pois as atualiza√ß√µes do gradiente t√™m impacto nos pesos.\n",
        "\n",
        "Uma maneira de resolver o problema do desaparecimento do gradiente √© usar redes de mem√≥ria de longo prazo, Long-Short Term Memory (LSTM). Redes LSTM s√£o um tipo especial de RNN que possuem tr√™s portas: entrada, esquecimento e sa√≠da. Essas portas controlam como as informa√ß√µes fluem para dentro, para fora e atrav√©s de suas unidades. A c√©lula LSTM guarda informa√ß√µes de itera√ß√µes anteriores e as compara com a entrada atual para determinar se novas informa√ß√µes ser√£o armazenadas e passadas adiante colah.\n",
        "\n",
        "## **Rede neural de Jordan Bird**\n",
        "\n",
        "O modelo proposto por Jordan Bird apresenta intervalos de tempo irregulares e √© caracterizado pela polifonia. Este utiliza tr√™s vari√°veis principais: pitch (altura dos sons), offset (in√≠cio temporal) e duration (dura√ß√£o), onde pitch representa as notas musicais, offset indica o momento de in√≠cio da nota em rela√ß√£o √† nota anterior e duration refere-se ao tempo de execu√ß√£o da nota.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## **Conceitos Chave**\n",
        "\n",
        "> ### 1. *Web Scraping*\n",
        " Processo empregado para extrair informa√ß√µes de servidores via requisi√ß√µes HTTP. Utilizaram-se as bibliotecas requests e BeutifulSoup.\n",
        "\n",
        "> ### 2. *Epoch*\n",
        "\n",
        "Uma Epoch seria a execu√ß√£o de uma etapa de treinamento para o conjunto de dados. A quantidade de Epochs pode ser definida no modelo e sua dura√ß√£o depende da quantidade de dados e estrutura da rede neural utilizada.\n",
        "\n",
        "> ### 3. *Cria√ß√£o de sequ√™ncias*\n",
        "\n",
        "Para o treinamento do modelo de rede neural, as musicas que tem seus eventos armazenados em arrays, s√£o utilizadas para criar as sequ√™ncias de notas. Por se tratar de um aprendizado supervisionado, para cada entrada haver√° uma sa√≠da rotulada. Assim a sa√≠da rotulada ser√° o evento que ocorre logo ap√≥s a sequ√™ncia de 100 notas que serve de entrada. S√£o produzidas, para um array de n eventos, (n-100) sequ√™ncias e sa√≠das rotuladas.\n",
        "\n",
        "\n",
        "> ### 4. *Dropout*\n",
        "\n",
        " A t√©cnica de Dropout √© utilizada para evitar o overfitting em modelos de Deep\n",
        "Learning, g que o modelo generalize bem para novos dados. Isso permite produzir composi√ß√µes que n√£o s√£o apenas varia√ß√µes das musicas de treinamento, trazendo originalidade e a diversidade as composi√ß√µes geradas.\n",
        "\n",
        "> ### 5. *Fun√ß√£o de Ativa√ß√£o - ReLU*\n",
        "\n",
        "ReLU(x) = max (0, x)\n",
        "Isso significa que, para qualquer valor de entrada ùë•x, a fun√ß√£o ReLU retorna ùë•x se ùë•x for positivo; caso contr√°rio, retorna 0. Em termos matem√°ticos:\n",
        "\n",
        "Se ùë•‚â•0x‚â•0, ent√£o ReLU(ùë•)=ùë•ReLU(x)=x.\n",
        "\n",
        "Se ùë•<0x<0, ent√£o ReLU(ùë•)=0ReLU(x)=0.\n",
        "\n",
        "A principal vantagem de usar a fun√ß√£o ReLU sobre outras fun√ß√µes de ativa√ß√£o √© que ela n√£o ativa todos os neur√¥nios ao mesmo tempo. Se a entrada de uma fun√ß√£o ReLu for negativa, ela ser√° convertida em zero e o neur√¥nio n√£o ser√° ativado, isso significa que, ao mesmo tempo, apenas alguns neur√¥nios s√£o ativados. Portanto, a fun√ß√£o ReLu √© computacionalmente eficiente, pois envolve opera√ß√µes simples. Ao contr√°rio de fun√ß√µes de ativa√ß√£o como a sigmoid e a tangente hiperb√≥lica, a ReLU n√£o sofre com o problema da satura√ß√£o para valores positivos. Isso permite que os gradientes durante o treinamento sejam maiores e, assim, a rede neural possa aprender mais rapidamente."
      ],
      "metadata": {
        "id": "69Ed6lD7vmi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exemplo de Aplica√ß√£o**\n",
        "\n",
        "Na implementa√ß√£o abaixo foi aplicado o Web Scraping para a obten√ß√£o das m√∫sicas no formato MIDI. Estas foram transpostas e salvas para o treinamento do modelo de Jordan Bird. Ao final, a partir da biblioteca fluidsynth, √© poss√≠vel gerar e reproduzir mus√≠cas a partir do treinamento do modelo.\n",
        "\n",
        "Para a execu√ß√£o dos c√≥digos presentes neste Colab, recomenda-se a execu√ß√£o por uma GPU dedicada devido ao tempo necess√°rio por Epoch no treinamento."
      ],
      "metadata": {
        "id": "4wfTEdMMxqFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementa√ß√£o**\n"
      ],
      "metadata": {
        "id": "FyFHbT8vygVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro, ser√° necess√°rio montar seu drive para armazenar os arquivos obtidos por Web Scraping e aqueles gerados durante a execu√ß√£o do modelo. Para isso foi criado o diret√≥rio /musicasComLSTM"
      ],
      "metadata": {
        "id": "1PAqg8f0lGH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "47WSkdIDxpjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8469d1-7a1b-4527-fff4-e8e77b87f384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dir = 'drive/MyDrive/musicasComLSTM'\n",
        "if not os.path.exists(dir):\n",
        "    os.makedirs(dir)"
      ],
      "metadata": {
        "id": "z27duPgolzjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/musicasComLSTM/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZNpFGbWmtBh",
        "outputId": "fbad8238-5ca3-4786-ea5c-07d42e3b1ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/musicasComLSTM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o Web Scraping, ser√° necess√°rio instalar as depend√™ncias abaixo"
      ],
      "metadata": {
        "id": "9tJWb2PBmLUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando depend√™ncias para Web Scraping\n",
        "!pip install bs4\n",
        "!pip install requests"
      ],
      "metadata": {
        "id": "pTWpYLWdmTZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70fb87e0-15a6-4c9a-e96c-3b45dc8c16bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O c√≥digo de Web Scraping abaixo utiliza das bibliotecas requests e BeautifulSoup para criar as requisi√ß√µes HTTP para extrair os componentes do site com tag \"a\" do HTML, buscando pelo elemento href. Nele tamb√©m √© criado o diret√≥rio de Obras, onde as m√∫sicas obtidas s√£o salvas."
      ],
      "metadata": {
        "id": "K-M54orV2SuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Web Scraping em http://kern.ccarh.org/cgi-bin/ksbrowse?l=/users/craig/classical/bach/371chorales\n",
        "from urllib.parse import urljoin, urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/musicasComLSTM/Obras'):\n",
        "    os.makedirs('/content/drive/MyDrive/musicasComLSTM/Obras')\n",
        "\n",
        "url0 = 'https://kern.humdrum.org/cgi-bin/ksdata?file=chor'\n",
        "url1 = '.krn&l=users/craig/classical/bach/371chorales&format=midi'\n",
        "\n",
        "songNumber = 0\n",
        "response = requests.get('http://kern.ccarh.org/cgi-bin/ksbrowse?l=/users/craig/classical/bach/371chorales')\n",
        "status = response.status_code\n",
        "\n",
        "content = response.content\n",
        "parser = BeautifulSoup(content, features='html.parser')\n",
        "body = parser.body\n",
        "\n",
        "for link in body.find_all('a'):\n",
        "    href = link.get('href')\n",
        "    url = urljoin(url0 + \"{:03d}\".format(songNumber) + url1, href)\n",
        "    filename = os.path.basename('chor' + \"{:03d}\".format(songNumber)  + '.mid')\n",
        "\n",
        "    if os.path.isfile(os.path.join('Obras', filename)):\n",
        "      continue\n",
        "\n",
        "    if href is not None and 'format=midi' in href:\n",
        "        response = requests.get(url)\n",
        "        status = response.status_code\n",
        "        if status == 200:\n",
        "            try:\n",
        "                with open(os.path.join('Obras', filename), 'wb') as file:\n",
        "                    file.write(response.content)\n",
        "                    songNumber += 1;\n",
        "            except:\n",
        "                print(f'File \\'{filename}\\' is corrupted or currently in use.')\n",
        "\n",
        "        else:\n",
        "            print(f'Failed to download \\'{filename}\\' file.')"
      ],
      "metadata": {
        "id": "V0n7VWPZmiqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ap√≥s concluir esta etapa, haver√° um diret√≥rio /Obras contendo todas as m√∫sicas obtidas no processo. Em sequ√™ncia, √© necess√°rio instalar a biblioteca music21 para manipular arqivos MIDI. Tamb√©m foi criado um diret√≥rio para conter as obras transpostas.\n",
        "\n"
      ],
      "metadata": {
        "id": "EJBh_2aIoDiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando biblioteca para explorar arquivos MIDI\n",
        "!pip install music21"
      ],
      "metadata": {
        "collapsed": true,
        "id": "itDkufqlokpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe684717-9d6c-4493-9a63-9bade1ebd4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: music21 in /usr/local/lib/python3.10/dist-packages (9.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from music21) (5.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from music21) (1.4.2)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.10/dist-packages (from music21) (3.0.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from music21) (3.7.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from music21) (10.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from music21) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from music21) (2.31.0)\n",
            "Requirement already satisfied: webcolors>=1.5 in /usr/local/lib/python3.10/dist-packages (from music21) (1.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foram importadas todas as bibliotecas necess√°rias para a estrutura√ß√£o do modelo e cria√ß√£o de entradas e sa√≠das rotuladas."
      ],
      "metadata": {
        "id": "5zytqLpPDq31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas necess√°rias para cria√ß√£o do dataset e modelo LSTM\n",
        "\n",
        "import pickle\n",
        "import numpy\n",
        "import glob\n",
        "from music21 import converter, instrument, note, stream, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Input\n",
        "import keras.utils as np_utils\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras import Model\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "L_sPyul2pFzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No diret√≥rio data ser√£o salvas as listas de eventos, dura√ß√µes e offsets das m√∫sicas lidas, para posteriormente utilizar na gera√ß√£o de sequ√™ncias. No diret√≥rio weights, ser√£o salvos todos os pesos que representem melhorias significativas ao modelo."
      ],
      "metadata": {
        "id": "ixONHMQ1EA7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = 'data'\n",
        "if not os.path.exists(dir):\n",
        "    os.makedirs(dir)\n",
        "dir = 'weights'\n",
        "if not os.path.exists(dir):\n",
        "    os.makedirs(dir)"
      ],
      "metadata": {
        "id": "U7ah7ibEtEuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fun√ß√£o get_notes() √© utilizada para a leitura dos arquivos MIDI e extrair as informa√ß√µes das musicas como eventos (se seria uma nota ou acorde), offsets e dura√ß√µes de cada evento. Essas informa√ß√µes s√£o extraidas junto a biblioteca Music21 e s√£o salvas no diret√≥rio data, al√©m de serem retornadas a fun√ß√£o train_network, onde s√£o definidos os eventos, offsets e dura√ß√µes unicos. Tamb√©m √© nesta fun√ßao onde se criam as sequ√™ncias e √© criado o modelo e iniciado o treinameto.\n",
        "\n",
        "A fun√ß√£o prepare_sequences √© utilizada para eventos, offsets e dura√ß√µes, onde s√£o mapeados os arrays de acordo com o dicion√°rio de eventos, offsets e dura√ß√µes √∫nicas e geradas as sequ√™ncias de input e seu output.\n",
        "\n",
        "O modelo de Jordan prop√µe o uso de uma camada de LSTM para eventos, offsets e dura√ß√µes. Os resultados destas s√£o concatenados e introduzidos a outras camadas intermedi√°rias. Neste modelo foi utilizada a fun√ß√£o de ativa√ß√£o ReLU e Dropout para evitar overfitting, junto ao otimizador Adam. Ao final do quinto LSTM da arquitetura proposta, os resultados s√£o separados de volta para eventos, offsets e dura√ß√µes. Para retomar o treinamento partindo de um peso, pode ser indicado no final da fun√ß√£o create_network o arquivo de pesos que se deseja utilizar.\n",
        "\n",
        "A fun√ß√£o train() seria utilizada para o treinamento do modelo, recebendo os inputs e outputs como parametros. As melhorias dos pesos s√£o salvas no diret√≥rio weights, e a quantidade de Epochs √© declarada n final da fun√ß√£o."
      ],
      "metadata": {
        "id": "-slVokgtEcyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria√ß√£o do modelo de gera√ß√£o de trechos musicais em MIDI usando LSTM (Modelo de Jordan Bird)\n",
        "\n",
        "def train_network():\n",
        "\t\"\"\" Train a Neural Network to generate music \"\"\"\n",
        "\tnotes, offsets, durations = get_notes()\n",
        "\n",
        "\tn_vocab_notes = len(set(notes))\n",
        "\tnetwork_input_notes, network_output_notes = prepare_sequences(notes, n_vocab_notes)\n",
        "\n",
        "\tn_vocab_offsets = len(set(offsets))\n",
        "\tnetwork_input_offsets, network_output_offsets = prepare_sequences(offsets, n_vocab_offsets)\n",
        "\n",
        "\tn_vocab_durations = len(set(durations))\n",
        "\tnetwork_input_durations, network_output_durations = prepare_sequences(durations, n_vocab_durations)\n",
        "\tmodel = create_network(network_input_notes, n_vocab_notes, network_input_offsets, n_vocab_offsets, network_input_durations, n_vocab_durations)\n",
        "\ttrain(model, network_input_notes, network_input_offsets, network_input_durations, network_output_notes, network_output_offsets, network_output_durations)\n",
        "\n",
        "\n",
        "def get_notes():\n",
        "\t\t\"\"\" Get all the notes and chords from the MIDI files \"\"\"\n",
        "\t\tnotes = []\n",
        "\t\toffsets = []\n",
        "\t\tdurations = []\n",
        "\n",
        "\t\t# Specify the full path to the directory containing MIDI files\n",
        "\t\tfor file in glob.glob(\"Obras/*.mid\"):\n",
        "\n",
        "\t\t\tmidi = converter.parse(file)  # Parse MIDI file\n",
        "\n",
        "\t\t\tprint(\"Parsing %s\" % file)\n",
        "\n",
        "\t\t\tnotes_to_parse = None\n",
        "\n",
        "\t\t\ttry: # file has instrument parts\n",
        "\t\t\t\ts2 = instrument.partitionByInstrument(midi)\n",
        "\t\t\t\tnotes_to_parse = s2.parts[0].recurse()\n",
        "\t\t\texcept: # file has notes in a flat structure\n",
        "\t\t\t\tnotes_to_parse = midi.flat.notes\n",
        "\n",
        "\t\t\toffsetBase = 0\n",
        "\t\t\tfor element in notes_to_parse:\n",
        "\t\t\t\tisNoteOrChord = False\n",
        "\n",
        "\t\t\t\tif isinstance(element, note.Note):\n",
        "\t\t\t\t\tnotes.append(str(element.pitch))\n",
        "\t\t\t\t\tisNoteOrChord = True\n",
        "\t\t\t\telif isinstance(element, chord.Chord):\n",
        "\t\t\t\t\tnotes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\t\t\t\t\tisNoteOrChord = True\n",
        "\n",
        "\t\t\t\tif isNoteOrChord:\n",
        "\t\t\t\t\toffsets.append(str(element.offset - offsetBase))\n",
        "\t\t\t\t\tdurations.append(str(element.duration.quarterLength))\n",
        "\t\t\t\t\tisNoteOrChord = False\n",
        "\t\t\t\t\toffsetBase = element.offset\n",
        "\n",
        "\t\tprint(\"Length of notes array:\", len(notes))\n",
        "\t\tprint(\"Length of offsets array:\", len(offsets))\n",
        "\t\tprint(\"Length of durations array:\", len(durations))\n",
        "\n",
        "\t\t# Salvando em arquivos binarios\n",
        "\t\twith open('data/notes', 'wb') as filepath:\n",
        "\t\t\tpickle.dump(notes, filepath)\n",
        "\n",
        "\t\twith open('data/durations', 'wb') as filepath:\n",
        "\t\t\tpickle.dump(durations, filepath)\n",
        "\n",
        "\t\twith open('data/offsets', 'wb') as filepath:\n",
        "\t\t\tpickle.dump(offsets, filepath)\n",
        "\n",
        "\t\treturn notes, offsets, durations\n",
        "\n",
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "\t\"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "\tsequence_length = 30\n",
        "\tprint(\"Length of notes array:\", len(notes))\n",
        "\t# verificar pitches unicos\n",
        "\tpitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "\t # dicionario para mapear o pitches\n",
        "\tnote_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "\tnetwork_input = []\n",
        "\tnetwork_output = []\n",
        "\n",
        "\t# cria√ß√£o de sequencias e seus respectivos outputs\n",
        "\tfor i in range(0, len(notes) - sequence_length, 1):\n",
        "\t\tsequence_in = notes[i:i + sequence_length]\n",
        "\t\tsequence_out = notes[i + sequence_length]\n",
        "\t\tnetwork_input.append([note_to_int[char] for char in sequence_in])\n",
        "\t\tnetwork_output.append(note_to_int[sequence_out])\n",
        "\n",
        "\tn_patterns = len(network_input)\n",
        "\n",
        "\t# reshape do input para a rede neural\n",
        "\tnetwork_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\t# normalizar inputs\n",
        "\tnetwork_input = network_input / float(n_vocab)\n",
        "\n",
        "\tnetwork_output = tf.keras.utils.to_categorical(network_output, num_classes=n_vocab)\n",
        "\n",
        "\treturn (network_input, network_output)\n",
        "\n",
        "def create_network(network_input_notes, n_vocab_notes, network_input_offsets, n_vocab_offsets, network_input_durations, n_vocab_durations):\n",
        "\n",
        "\t# Parte da rede que considera apenas as sequencias de eventos\n",
        "\tinputNotesLayer = Input(shape=(network_input_notes.shape[1], network_input_notes.shape[2]))\n",
        "\tinputNotes = LSTM(\n",
        "\t\t256,\n",
        "\t\tinput_shape=(network_input_notes.shape[1], network_input_notes.shape[2]),\n",
        "\t\treturn_sequences=True\n",
        "\t)(inputNotesLayer)\n",
        "\tinputNotes = Dropout(0.2)(inputNotes)\n",
        "\n",
        "\t# Parte da rede que considera apenas as sequencias de offsets\n",
        "\tinputOffsetsLayer = Input(shape=(network_input_offsets.shape[1], network_input_offsets.shape[2]))\n",
        "\tinputOffsets = LSTM(\n",
        "\t\t256,\n",
        "\t\tinput_shape=(network_input_offsets.shape[1], network_input_offsets.shape[2]),\n",
        "\t\treturn_sequences=True\n",
        "\t)(inputOffsetsLayer)\n",
        "\tinputOffsets = Dropout(0.2)(inputOffsets)\n",
        "\n",
        "\t# Parte da rede que considera apenas as sequencias de dura√ß√µes\n",
        "\tinputDurationsLayer = Input(shape=(network_input_durations.shape[1], network_input_durations.shape[2]))\n",
        "\tinputDurations = LSTM(\n",
        "\t\t256,\n",
        "\t\tinput_shape=(network_input_durations.shape[1], network_input_durations.shape[2]),\n",
        "\t\treturn_sequences=True\n",
        "\t)(inputDurationsLayer)\n",
        "\tinputDurations = Dropout(0.2)(inputDurations)\n",
        "\n",
        "\t#Concatena√ß√£o de eventos, offset e dura√ß√£o\n",
        "\tinputs = concatenate([inputNotes, inputOffsets, inputDurations])\n",
        "\n",
        "\t# LSTMs que consideram os aprendizados individuais das outras etapas\n",
        "\tx = LSTM(512, return_sequences=True)(inputs)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\tx = LSTM(512)(x)\n",
        "\tx = BatchNorm()(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\tx = Dense(256, activation='relu')(x)\n",
        "\n",
        "\t#Separa√ß√£o de evento, offset e dura√ß√£o\n",
        "\n",
        "\t# Classifica os eventos\n",
        "\toutputNotes = Dense(128, activation='relu')(x)\n",
        "\toutputNotes = BatchNorm()(outputNotes)\n",
        "\toutputNotes = Dropout(0.3)(outputNotes)\n",
        "\toutputNotes = Dense(n_vocab_notes, activation='softmax', name=\"Note\")(outputNotes)\n",
        "\n",
        "\t# Classifica o offset\n",
        "\toutputOffsets = Dense(128, activation='relu')(x)\n",
        "\toutputOffsets = BatchNorm()(outputOffsets)\n",
        "\toutputOffsets = Dropout(0.3)(outputOffsets)\n",
        "\toutputOffsets = Dense(n_vocab_offsets, activation='softmax', name=\"Offset\")(outputOffsets)\n",
        "\n",
        "\t# Classifica a dura√ß√£o\n",
        "\toutputDurations = Dense(128, activation='relu')(x)\n",
        "\toutputDurations = BatchNorm()(outputDurations)\n",
        "\toutputDurations = Dropout(0.3)(outputDurations)\n",
        "\toutputDurations = Dense(n_vocab_durations, activation='softmax', name=\"Duration\")(outputDurations)\n",
        "\n",
        "\t# Informa os inputs e outputs do modelo\n",
        "\tmodel = Model(inputs=[inputNotesLayer, inputOffsetsLayer, inputDurationsLayer], outputs=[outputNotes, outputOffsets, outputDurations])\n",
        "\n",
        "\t#Otimizador Adam tem melhores resultados que RMSprop, para loss utilizar categorical_crossentropy\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "\t# Carregar os pesos mais recentes para continuar o treinamento\n",
        "\t# model.load_weights(\"weights/arquivo.hdf5\")\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def train(model, network_input_notes, network_input_offsets, network_input_durations, network_output_notes, network_output_offsets, network_output_durations):\n",
        "\t\"\"\" train the neural network \"\"\"\n",
        "\tfilepath = \"weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "\tcheckpoint = ModelCheckpoint(\n",
        "\t\tfilepath,\n",
        "\t\tmonitor='loss',\n",
        "\t\tverbose=0,\n",
        "\t\tsave_best_only=True,\n",
        "\t\tmode='min'\n",
        "\t)\n",
        "\tcallbacks_list = [checkpoint]\n",
        "\n",
        "\tmodel.fit([network_input_notes, network_input_offsets, network_input_durations], [network_output_notes, network_output_offsets, network_output_durations], epochs=100, batch_size=64, callbacks=callbacks_list, verbose=1)"
      ],
      "metadata": {
        "id": "tcTdtOl7q4bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fun√ß√£o train_network inicia o treinamento."
      ],
      "metadata": {
        "id": "RywdeJMOMPEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executando treinamento do modelo com dataset obtido\n",
        "train_network()"
      ],
      "metadata": {
        "id": "P8kQQYn9tRtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ap√≥s o treinamento, s√£o lidos os arquivos bin√°rios para a gera√ß√£o de sequ√™ncias na fun√ß√£o generate() e chamada a fun√ß√£o generate_notes(), que partindo de eventos, dura√ß√µes e offsets aleat√≥rios, faz a gera√ß√£o da nota em sequencia, sendo sempre escolhida a nota de maior probabilidade.\n",
        "\n",
        "Ao final de generate() temos a fun√ß√£o create_midi(), que produz um arquivo MIDI pelas notas geradas e o salva no diret√≥rio musicasComLSTM."
      ],
      "metadata": {
        "id": "PPizpZO1Mmsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C√≥digo para gera√ßao de trechos musicais usando o modelo LSTM para preditar as notas, duracoes e offsets\n",
        "\n",
        "def generate():\n",
        "\t\"\"\" Generate a piano midi file \"\"\"\n",
        "\t#load the notes used to train the model\n",
        "\twith open('data/notes', 'rb') as filepath:\n",
        "\t\tnotes = pickle.load(filepath)\n",
        "\n",
        "\twith open('data/durations', 'rb') as filepath:\n",
        "\t\tdurations = pickle.load(filepath)\n",
        "\n",
        "\twith open('data/offsets', 'rb') as filepath:\n",
        "\t\toffsets = pickle.load(filepath)\n",
        "\n",
        "\t# Get all pitch names\n",
        "\t#pitchnames = sorted(set(item for item in notes))\n",
        "\t# Get all pitch names\n",
        "\t#n_vocab = len(set(notes))\n",
        "\n",
        "\n",
        "\tnotenames = sorted(set(item for item in notes))\n",
        "\tn_vocab_notes = len(set(notes))\n",
        "\tnetwork_input_notes, normalized_input_notes = prepare_sequences(notes, notenames, n_vocab_notes)\n",
        "\n",
        "\toffsetnames = sorted(set(item for item in offsets))\n",
        "\tn_vocab_offsets = len(set(offsets))\n",
        "\tnetwork_input_offsets, normalized_input_offsets = prepare_sequences(offsets, offsetnames, n_vocab_offsets)\n",
        "\n",
        "\tdurationames = sorted(set(item for item in durations))\n",
        "\tn_vocab_durations = len(set(durations))\n",
        "\tnetwork_input_durations, normalized_input_durations = prepare_sequences(durations, durationames, n_vocab_durations)\n",
        "\n",
        "\t#model = create_network(network_input_notes, n_vocab_notes, network_input_offsets, n_vocab_offsets, network_input_durations, n_vocab_durations)\n",
        "\n",
        "\tmodel = create_network(normalized_input_notes, n_vocab_notes, normalized_input_offsets, n_vocab_offsets, normalized_input_durations, n_vocab_durations)\n",
        "\n",
        "\n",
        "\t#network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "\t#model = create_network(normalized_input, n_vocab)\n",
        "\n",
        "\tprediction_output = generate_notes(model, network_input_notes, network_input_offsets, network_input_durations, notenames, offsetnames, durationames, n_vocab_notes, n_vocab_offsets, n_vocab_durations)\n",
        "\tcreate_midi(prediction_output)\n",
        "\n",
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "\t\"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "\t# map between notes and integers and back\n",
        "\tnote_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "\tsequence_length = 30\n",
        "\tnetwork_input = []\n",
        "\toutput = []\n",
        "\tfor i in range(0, len(notes) - sequence_length, 1):\n",
        "\t\tsequence_in = notes[i:i + sequence_length]\n",
        "\t\tsequence_out = notes[i + sequence_length]\n",
        "\t\tnetwork_input.append([note_to_int[char] for char in sequence_in])\n",
        "\t\toutput.append(note_to_int[sequence_out])\n",
        "\n",
        "\tn_patterns = len(network_input)\n",
        "\n",
        "\t# reshape the input into a format compatible with LSTM layers\n",
        "\tnormalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\t# normalize input\n",
        "\tnormalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "\treturn (network_input, normalized_input)\n",
        "\n",
        "def create_network(network_input_notes, n_vocab_notes, network_input_offsets, n_vocab_offsets, network_input_durations, n_vocab_durations):\n",
        "\t# Branch of the network that considers notes\n",
        "\tinputNotesLayer = Input(shape=(network_input_notes.shape[1], network_input_notes.shape[2]))\n",
        "\tinputNotes = LSTM(\n",
        "\t\t256,\n",
        "\t\tinput_shape=(network_input_notes.shape[1], network_input_notes.shape[2]),\n",
        "\t\treturn_sequences=True\n",
        "\t)(inputNotesLayer)\n",
        "\tinputNotes = Dropout(0.2)(inputNotes)\n",
        "\n",
        "\t# Branch of the network that considers note offset\n",
        "\tinputOffsetsLayer = Input(shape=(network_input_offsets.shape[1], network_input_offsets.shape[2]))\n",
        "\tinputOffsets = LSTM(\n",
        "\t\t256,\n",
        "\t\tinput_shape=(network_input_offsets.shape[1], network_input_offsets.shape[2]),\n",
        "\t\treturn_sequences=True\n",
        "\t)(inputOffsetsLayer)\n",
        "\tinputOffsets = Dropout(0.2)(inputOffsets)\n",
        "\n",
        "\t# Branch of the network that considers note duration\n",
        "\tinputDurationsLayer = Input(shape=(network_input_durations.shape[1], network_input_durations.shape[2]))\n",
        "\tinputDurations = LSTM(\n",
        "\t\t256,\n",
        "\t\tinput_shape=(network_input_durations.shape[1], network_input_durations.shape[2]),\n",
        "\t\treturn_sequences=True\n",
        "\t)(inputDurationsLayer)\n",
        "\t#inputDurations = Dropout(0.3)(inputDurations)\n",
        "\tinputDurations = Dropout(0.2)(inputDurations)\n",
        "\n",
        "\t#Concatentate the three input networks together into one branch now\n",
        "\tinputs = concatenate([inputNotes, inputOffsets, inputDurations])\n",
        "\n",
        "\t# A cheeky LSTM to consider everything learnt from the three separate branches\n",
        "\tx = LSTM(512, return_sequences=True)(inputs)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\tx = LSTM(512)(x)\n",
        "\tx = BatchNorm()(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\tx = Dense(256, activation='relu')(x)\n",
        "\n",
        "\t#Time to split into three branches again...\n",
        "\n",
        "\t# Branch of the network that classifies the note\n",
        "\toutputNotes = Dense(128, activation='relu')(x)\n",
        "\toutputNotes = BatchNorm()(outputNotes)\n",
        "\toutputNotes = Dropout(0.3)(outputNotes)\n",
        "\toutputNotes = Dense(n_vocab_notes, activation='softmax', name=\"Note\")(outputNotes)\n",
        "\n",
        "\t# Branch of the network that classifies the note offset\n",
        "\toutputOffsets = Dense(128, activation='relu')(x)\n",
        "\toutputOffsets = BatchNorm()(outputOffsets)\n",
        "\toutputOffsets = Dropout(0.3)(outputOffsets)\n",
        "\toutputOffsets = Dense(n_vocab_offsets, activation='softmax', name=\"Offset\")(outputOffsets)\n",
        "\n",
        "\t# Branch of the network that classifies the note duration\n",
        "\toutputDurations = Dense(128, activation='relu')(x)\n",
        "\toutputDurations = BatchNorm()(outputDurations)\n",
        "\toutputDurations = Dropout(0.3)(outputDurations)\n",
        "\toutputDurations = Dense(n_vocab_durations, activation='softmax', name=\"Duration\")(outputDurations)\n",
        "\n",
        "\t# Tell Keras what our inputs and outputs are\n",
        "\tmodel = Model(inputs=[inputNotesLayer, inputOffsetsLayer, inputDurationsLayer], outputs=[outputNotes, outputOffsets, outputDurations])\n",
        "\n",
        "\t#Adam seems to be faster than RMSProp and learns better too\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\tmodel.load_weights(\"weights_transposed/weights-improvement-06-0.5417-bigger.hdf5\")\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def generate_notes(model, network_input_notes, network_input_offsets, network_input_durations, notenames, offsetnames, durationames, n_vocab_notes, n_vocab_offsets, n_vocab_durations):\n",
        "\t\"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "\t# pick a random sequence from the input as a starting point for the prediction\n",
        "\t# start = numpy.random.randint(0, len(network_input_notes)-1)\n",
        "\t# start2 = numpy.random.randint(0, len(network_input_offsets)-1)\n",
        "\t# start3 = numpy.random.randint(0, len(network_input_durations)-1)\n",
        "\n",
        "\tstart = 0\n",
        "\tstart2 = 0\n",
        "\tstart3 = 0\n",
        "\n",
        "\tint_to_note = dict((number, note) for number, note in enumerate(notenames))\n",
        "\tprint(int_to_note)\n",
        "\tint_to_offset = dict((number, note) for number, note in enumerate(offsetnames))\n",
        "\tint_to_duration = dict((number, note) for number, note in enumerate(durationames))\n",
        "\n",
        "\tpattern = network_input_notes[start]\n",
        "\tpattern2 = network_input_offsets[start2]\n",
        "\tpattern3 = network_input_durations[start3]\n",
        "\tprediction_output = []\n",
        "\n",
        "\t# generate notes or chords\n",
        "\tfor note_index in range(100):\n",
        "\t\tnote_prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\t\tpredictedNote = note_prediction_input[-1][-1][-1]\n",
        "\t\t#print(note_prediction_input.shape)\n",
        "\n",
        "\t\t#print(n_vocab_notes)\n",
        "\t\t#print(n_vocab_offsets)\n",
        "\t\t#print(n_vocab_durations)\n",
        "\n",
        "\n",
        "\t\tnote_prediction_input = note_prediction_input / float(n_vocab_notes)\n",
        "\n",
        "\t\toffset_prediction_input = numpy.reshape(pattern2, (1, len(pattern2), 1))\n",
        "\t\toffset_prediction_input = offset_prediction_input / float(n_vocab_offsets)\n",
        "\n",
        "\t\tduration_prediction_input = numpy.reshape(pattern3, (1, len(pattern3), 1))\n",
        "\t\tduration_prediction_input = duration_prediction_input / float(n_vocab_durations)\n",
        "\n",
        "\t\tprediction = model.predict([note_prediction_input, offset_prediction_input, duration_prediction_input], verbose=0)\n",
        "\n",
        "\t\tindex = numpy.argmax(prediction[0])\n",
        "\t\t#print(index)\n",
        "\t\tresult = int_to_note[index]\n",
        "\t\t#print(result)\n",
        "\n",
        "\t\toffset = numpy.argmax(prediction[1])\n",
        "\t\toffset_result = int_to_offset[offset]\n",
        "\t\t#print(\"offset\")\n",
        "\t\t#print(offset_result)\n",
        "\n",
        "\t\tduration = numpy.argmax(prediction[2])\n",
        "\t\tduration_result = int_to_duration[duration]\n",
        "\t\t#print(\"duration\")\n",
        "\t\t#print(duration_result)\n",
        "\n",
        "\t\tprint(\"Next note: \" + str(int_to_note[predictedNote]) + \" - Duration: \" + str(int_to_duration[duration]) + \" - Offset: \" + str(int_to_offset[offset]))\n",
        "\n",
        "\n",
        "\t\t#\n",
        "\t\tprediction_output.append([result, offset_result, duration_result])\n",
        "\n",
        "\t\tpattern.append(index)\n",
        "\t\tpattern2.append(offset)\n",
        "\t\tpattern3.append(duration)\n",
        "\t\tpattern = pattern[1:len(pattern)]\n",
        "\t\tpattern2 = pattern2[1:len(pattern2)]\n",
        "\t\tpattern3 = pattern3[1:len(pattern3)]\n",
        "\n",
        "\treturn prediction_output\n",
        "\n",
        "def create_midi(prediction_output_all):\n",
        "\t\"\"\" convert the output from the prediction to notes and create a midi file\n",
        "\t\tfrom the notes \"\"\"\n",
        "\toffset = 0\n",
        "\toutput_notes = []\n",
        "\n",
        "\t#prediction_output = prediction_output_all\n",
        "\n",
        "\toffsets = []\n",
        "\tdurations = []\n",
        "\tnotes = []\n",
        "\n",
        "\tfor x in prediction_output_all:\n",
        "\t\tprint(x)\n",
        "\t\tnotes = numpy.append(notes, x[0])\n",
        "\t\ttry:\n",
        "\t\t\toffsets = numpy.append(offsets, float(x[1]))\n",
        "\t\texcept:\n",
        "\t\t\tnum, denom = x[1].split('/')\n",
        "\t\t\tx[1] = float(num)/float(denom)\n",
        "\t\t\toffsets = numpy.append(offsets, float(x[1]))\n",
        "\n",
        "\t\tdurations = numpy.append(durations, x[2])\n",
        "\n",
        "\tprint(\"---\")\n",
        "\tprint(notes)\n",
        "\tprint(offsets)\n",
        "\tprint(durations)\n",
        "\n",
        "\t# create note and chord objects based on the values generated by the model\n",
        "\tx = 0 # this is the counter\n",
        "\tfor pattern in notes:\n",
        "\t\t# pattern is a chord\n",
        "\t\tif ('.' in pattern) or pattern.isdigit():\n",
        "\t\t\tnotes_in_chord = pattern.split('.')\n",
        "\t\t\tnotes = []\n",
        "\t\t\tfor current_note in notes_in_chord:\n",
        "\t\t\t\tnew_note = note.Note(int(current_note))\n",
        "\t\t\t\tnew_note.storedInstrument = instrument.Piano()\n",
        "\t\t\t\tnotes.append(new_note)\n",
        "\t\t\tnew_chord = chord.Chord(notes)\n",
        "\n",
        "\t\t\ttry:\n",
        "\t\t\t\tnew_chord.duration.quarterLength = float(durations[x])\n",
        "\t\t\texcept:\n",
        "\t\t\t\tnum, denom = durations[x].split('/')\n",
        "\t\t\t\tnew_chord.duration.quarterLength = float(num)/float(denom)\n",
        "\n",
        "\t\t\tnew_chord.offset = offset\n",
        "\n",
        "\t\t\toutput_notes.append(new_chord)\n",
        "\t\t# pattern is a note\n",
        "\t\telse:\n",
        "\t\t\tnew_note = note.Note(pattern)\n",
        "\t\t\tnew_note.offset = offset\n",
        "\t\t\tnew_note.storedInstrument = instrument.Piano()\n",
        "\t\t\ttry:\n",
        "\t\t\t\tnew_note.duration.quarterLength = float(durations[x])\n",
        "\t\t\texcept:\n",
        "\t\t\t\tnum, denom = durations[x].split('/')\n",
        "\t\t\t\tnew_note.duration.quarterLength = float(num)/float(denom)\n",
        "\n",
        "\t\t\toutput_notes.append(new_note)\n",
        "\n",
        "\t\t# increase offset each iteration so that notes do not stack\n",
        "\t\ttry:\n",
        "\t\t\toffset += offsets[x]\n",
        "\t\texcept:\n",
        "\t\t\tnum, denom = offsets[x].split('/')\n",
        "\t\t\toffset += num/denom\n",
        "\n",
        "\t\tx = x+1\n",
        "\n",
        "\tmidi_stream = stream.Stream(output_notes)\n",
        "\n",
        "\tmidi_stream.write('midi', fp='obra.mid')"
      ],
      "metadata": {
        "id": "fsoPTwn6Mj3t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uma ideia de Projeto de Aplica√ß√£o**\n",
        "\n",
        "A partir do que foi exposto neste colab, podem ser realizadas adapta√ß√µes no c√≥digo para a leitura de outros generos musicais, incluindo musicas com percurs√µes, que neste projeto n√£o s√£o capturadas. Outras possiveis aplica√ß√µes seriam de novas arquiteturas de redes neurais, testando outras abordagens ou tamb√©m de se implementar a gera√ß√£o de m√∫sicas de diferentes instrumentos."
      ],
      "metadata": {
        "id": "vuisqDoJ0oTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Refer√™ncias**\n",
        "\n",
        "*   Fonte de dados: [corais de Bach](http://kern.ccarh.org/cgi-bin/ksbrowse?l=/users/craig/classical/bach/371chorales)\n",
        "*   MED, B. (1996). Teoria da m√∫sica, volume 996. Bras√≠lia: Musimed.\n",
        "*   Bird, J. (2020). Keras-LSTM-Music-Generator. [Modelo de Jordan Bird no GitHub](https://github.com/jordan-bird/Keras-LSTM-Music-Generator). Acessado em: 20 de Maio de 2024.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7LtXrRFr4hg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **V√≠deo e GitHub**\n",
        "\n",
        "[Link do reposit√≥rio no GitHub](https://github.com/Leonardo-Biagiotti/Inteligencia-Artificial-7G/tree/main)\n",
        "\n",
        "[Link no v√≠deo no Youtube](https://youtu.be/RJgJj5PE5P0)"
      ],
      "metadata": {
        "id": "ZGpU-v6CnTaG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kwoGZeSLRsX"
      },
      "source": [
        "# **Conclus√£o**\n",
        "\n",
        "As redes neurais artificiais (RNAs) se consolidam como ferramentas poderosas, demonstrando a capacidade de aprender e reproduzir resultados surpreendentes mesmo com conjuntos de dados limitados. Essa caracter√≠stica abre um leque de possibilidades promissoras em diversos setores, principalmente na √°rea audiovisual.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ap√™ndice**\n",
        "\n",
        "Link da Apresenta√ß√£o no YouTube:\n"
      ],
      "metadata": {
        "id": "EHohsrFbpksT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('RJgJj5PE5P0') # https://youtu.be/RJgJj5PE5P0"
      ],
      "metadata": {
        "id": "LqJACWuip3YG",
        "outputId": "9eeb00d1-77d4-4fda-f536-af51f765484a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x786db073c250>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"400\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/RJgJj5PE5P0\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoXFRcaFxYeHRcfHyEiIyEiIDEmKigoOi0xMy8qNzE1PlBCPjpTOy04RGFFTVNiW11bMkJlbWVYbFBZW1cBERISGBYXJRcVKFc2LTZXV1dXV1dXV1ddV1dXV1dXV1dXXVdXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAABQYBAgQDB//EADkQAQACAQEECAQFAwQCAwAAAAABAgMRBBIUkhMhMVFSU5HRBRVU4SJBYXGxMnKBBjOywTRiI6Hx/8QAFwEBAQEBAAAAAAAAAAAAAAAAAAECA//EABkRAQEBAQEBAAAAAAAAAAAAAAAREgECMf/aAAwDAQACEQMRAD8A+fgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACz8Hi8VOWDg8XipywzpYrAs/B4vFTlg4TF4qcsGiKwLPwmLxU5YOExeKnLBpYrAs/B4vFTlg4PF4qcsGkisCz8Hi8VOWDg8XipywUisCz8Hi8VOWDg8XipywaXKsCz8Hi8VOWDg8XipywaIrAs/B4vFTlg4PF4qcsFMqwLPweLxU5YODxeKnLBUisCz8Hi8VOWDg8XipywaWKwLPweLxU5YODxeKnLBoisCz8Hi8VOWDg8XipywaIrAs/B4vFTlg4PF4qcsGjKsCz8Hi8VOWDg8XipywaSKwJnafh+CbzM7VWvZ1bvZ1fu8vluD62vL92kRYlPluD62vL9z5bg+try/cEWJT5bg+try/c+W4Pra8v3BFiU+W4Pra8v3PluD6yvL9wRYlPluD6yvL9z5bg+sry/cEWJT5bg+spy/c+W4PrK8v3BFiU+W4PrK8v3PluD6yvL9wRYlPluD62nL9z5bg+spy/cEWJT5bg+spy/c+W4Pra8v3BFiU+W4Pra8v3PluD6yvL9wRYlPluD6yvL9z5bg+sry/cEWJT5bg+sry/c+W4PrK8v3BFiU+W4Pra8v3PluD62vL9wRYlPluD62vL9z5bg+spy/cEWJT5bg+spy/c+W4PrKcv3BFiU+W4PrKcv3aZfh+GtbTG11tMRMxGnbPd2gkRE/MsndX0Z+ZZO6vozGqn9hjWba9zt3Y7o9EP8C2q2S2Te06ojs/dMmep31xjdjuj0N2O6PRkXPU1xjdjuj0N2O6PRkM9NcY3Y7o9Ddjuj0ZDPTXGN2O6PQ3Y7o9GQz01xjdjuj0N2O6PRkM9NcY3Y7o9Ddjuj0ZDPTXGN2O6PQ3Y7o9GQz01xjdjuj0N2O6PRkM9NcY3Y7o9Ddjuj0ZCdTXGN2O6PQ3Y7o9GQz01xjdjuj0N2O6PRkM9XXGN2O6PQ3Y7o9GQz1Nca9HXwx6QdFXw19IbDbHeteir4a+kHR18NfSGwI16Ovhr6QdFXw19IbArXo6+CvpB0dfDX0hsA16Ovhr6QdFXw19IbANOir4a+kM9HXw19IbANejr4a+kHRV8NfSGwDToq+GvpDPRV8NfSGwDToq+GvpDPRV8NfSGwDXoq+GvpB0VfDX0hsA06Kvhr6QdFXw19IbgNeir4a+kHRV8NfSGwDToq+GvpDPRV8NfSGwDToq+GvpB0VfDX0huA06Kvhr6QdFXw19IbgjToq+GvpB0VfDX0huAooDLqmv8ATX9eX+2P5WBX/wDTX9eX+2P5WBrjHr6ADIAAAAAAAD1x7Pe1L3rXWlNN6e7XsaUpNrRWsa2mYiI/VJfC88Y8N5t/t2y0reP/AFmt4n3/AMMYcE7NfPe3bi/BT9bz2T6dfoNRH5sNsdppeNLR2w2z4JxzWLaazETp+ca9mv6pTbsNbbRts2jrpSLV6/z/AAuKMNZ2acltd/porNtdfw7szIRxvTPhnHaa2016uyde2Nfyd3xLZ646zuYI6PWNzNF5tr+/5dfd1N8mw46582sT0WLHW+7E9czMRpGv7yJEUOyk1y5KRTZvznWtbT+Lu657P3dG2bJWME5OjrjvW8V0rk34mJie3rnSeoIix1fD8Fb2vN9Zpjpa8xHVrp2Rr+8veIxZNnz3jDuXpuaaWmY0m2n5/mERwnK/Da0nHS2CLxMVm+ScsVmNe6Nfy/WOtzRs+LHiy2tTpLUzzjr+KYiY0/PT1CIwStdhply7NuRuUy1ta1dddN3XXSZ79PzZ2jY6zhyWnBXDNNJrpli29GvXExrPWERIktux4qTXHTFM3tXHOu9OsTMR1RH6/wDb2y7FWcWbXBXFald6umXet1THVaNf1/QIiJrOkTpOk9k97fPhnHeaW03o7dJ1/hI/EMtJ2bZojFETNb6TvT+H8XX++v6m07Fji+10pXS2OK3p1z/TpG9H/wB6ixFCQjZqxw9IxzfJaJvaInSZif6Y/TqjWf3em27JWME5OjpjvW8VmKZN+JiYnt650nqEiLHZ8M2SMuS2saxSk33YmI3tNNI1ns65dG1bHHRb84q4rResbtcm9Fon/MzrARFia4bZ52q+zximI/FpfeneiYjXs7NOrRyWriyYMt6YujtjmmmlpnWLTMdev5hHHhxWyWitI1tPZDSI17Hd8E/8vF+9v+MuXZsvR3x3iNZrNbaft1g98nwzNWs2tTSIjWY3q6xHfprq2r8JzzGsY+rt/qr7vTadmpm6TLgvrPXe+O0aWr+czE/nDTYf/H2z+yn/ADgWPKdgy65I3P8AbiJt1xOkerniNeqO1J/Cdo6LFtF9NYicOsd9ZtMTHoY9ljBmy5J68eGIvT/2mf8Ab9/8BEfnwXxWmmSu7aNNY/8Ax5u74zMznmZnWdzH/wAIcIgAIAAAAAAAAAAAAooDLqmv9Nf15f7Y/lYFf/01/Xl/tj+Vga4x6+gAyAAAAAAAA9q59MVsenbattde6JjTT/L02nbrZceKkx1Ujt8U9kTP+IiHKC13z8S1z5clsetctZram9+Wkdk6fo1y7bScUYqYd2nSRfWb6zPVMaT1fq4gK7Mm2UjFkx4sU0jJu72t97snWNOqG8/Etc17zjia3rFLUme2IiI7e/q1cAFduLbceO8Wx4Ziulq2ib6zaJjTt06mMu2U6G2LHi3azaLazbenWNf0cYFdfw7JeuSdzH0kWratqR+dfz7HbkiKbLnjoLYovNIjfmZtaYnWe2I6oj+URW0xOsTMT+jNrzbrtaZn9Z1Cuy22477s5cG9esRXei+7vRHZrGjx4n/4ZxbvVOTf11/TTTRzgV2Y/iE06Ca1jXFFo651i0TMzP8AOjTPlwzWYx4JpafznJvafpEaQ5gK677dM5seWKxE0imka6/0xHs9LbfjiM0Uwbs5azEzN9dNZ16urscAFdV9qrbBTHak71NYraLadUzrOsaf9t7fEJnaZz7kdc9dde2NNJjX9nEBXbT4hMZ7ZZpExaJrNddPwzGmkT+zGXbKdDbFjxbtZtFtZtvTrGv6OMCvfY9p6K0zuxatqzW1Z/Os9sM5suLq6PDNZ111m+9/jshzgO2PiGm02z7nbvfh3u+Jjt0/V44to3cWXHu67+5169m7Mz/28AHvsW09Dlpk3d7d16tdNeqY7f8AL0naMP4d3ZtNJievLNomO7scgFd/HY6xfocG5a1ZrMzfe0ie3SNIc+HaNzHmpu69JFY117NJ1eAD2x7Ru4stN3XpNzr17N2dXpm2618GPFMdVPz/ADnuj/GsuUB77XtHS33t3T8NY0117IiP+ngAAAgAAAAAAAAAAACigMuqa/01/Xl/tj+VgUjFmvTXcvauvbuzMfw9eOzedk5591rPeVchTeOzedk559zjs3nZOefcqZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KZXIU3js3nZOefc47N52Tnn3KuVyFN47N52Tnn3OOzedk559ymVyFN47N52Tnn3OOzedk559ymVyFN47N52Tnn3OOzedk559ymVyFN47N52Tnn3OOzedk559ymVyFN47N52Tnn3OOzedk559yplchTeOzedk559zjs3nZOefcplchTeOzedk559zjs3nZOefcplchTeOzedk559zjs3nZOefcplchTeOzedk559zjs3nZOefcplchTeOzedk559zjs3nZOefcplchTeOzedk559zjs3nZOefcplchTeOzedk559zjs3nZOefcplchTeOzedk559zjs3nZOefcplzgI2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//Z\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8crUBC3IQ3U_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BluFtfHuCGzm",
        "cellView": "form"
      },
      "source": [
        "#@title **Avalia√ß√£o**\n",
        "Referencial_Teorico = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Conceitos_Chave = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Exemplo_Aplicacao = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Ideia_Projeto = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Conclusao = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "2Gqw7hUZHyle",
        "cellView": "form",
        "outputId": "8ea25355-0b96-404b-df15-0a0978889502"
      },
      "source": [
        "#@title **Nota Final**\n",
        "nota = Referencial_Teorico + Conceitos_Chave + 2*Exemplo_Aplicacao + 2*Ideia_Projeto + Conclusao\n",
        "\n",
        "nota = nota / 7\n",
        "\n",
        "print(f'Nota final do trabalho {nota :.1f}')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "alunos = pd.DataFrame()\n",
        "\n",
        "lista_tia = []\n",
        "lista_nome = []\n",
        "\n",
        "for i in range(1,6):\n",
        "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n",
        "\n",
        "alunos['tia'] = lista_tia\n",
        "alunos['nome'] = lista_nome\n",
        "alunos['nota'] = np.round(nota,1)\n",
        "print()\n",
        "display(alunos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nota final do trabalho 0.0\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        tia                               nome  nota\n",
              "0  10390339          LEONARDO BIAGIOTTI BELOTI   0.0\n",
              "1  10389222      LUCAS DAMASCENO DA CUNHA LIMA   0.0\n",
              "2  10389472   LUCAS IUDI CORREGLIANO GALLINARI   0.0\n",
              "3  10389723            THIAGO AIDAR FIGUEIREDO   0.0\n",
              "4  10388769                            YIOU WU   0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-277b3da3-95d1-437a-9a3b-48daaeeb3d5f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tia</th>\n",
              "      <th>nome</th>\n",
              "      <th>nota</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10390339</td>\n",
              "      <td>LEONARDO BIAGIOTTI BELOTI</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10389222</td>\n",
              "      <td>LUCAS DAMASCENO DA CUNHA LIMA</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10389472</td>\n",
              "      <td>LUCAS IUDI CORREGLIANO GALLINARI</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10389723</td>\n",
              "      <td>THIAGO AIDAR FIGUEIREDO</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10388769</td>\n",
              "      <td>YIOU WU</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-277b3da3-95d1-437a-9a3b-48daaeeb3d5f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-277b3da3-95d1-437a-9a3b-48daaeeb3d5f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-277b3da3-95d1-437a-9a3b-48daaeeb3d5f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e138cab-932f-4c96-9804-fa30818d2dfd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e138cab-932f-4c96-9804-fa30818d2dfd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e138cab-932f-4c96-9804-fa30818d2dfd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_53bec1a5-d017-4673-8371-bfd674c546c1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('alunos')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_53bec1a5-d017-4673-8371-bfd674c546c1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('alunos');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "alunos",
              "summary": "{\n  \"name\": \"alunos\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tia\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"10389222\",\n          \"10388769\",\n          \"10389472\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nome\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \" LUCAS DAMASCENO DA CUNHA LIMA\",\n          \" YIOU WU\",\n          \" LUCAS IUDI CORREGLIANO GALLINARI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}